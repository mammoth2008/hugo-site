# 耐心算法

*人工智能如何教会我们忘记学习*

指环王重映

去年，麻省理工学院媒体实验室的研究人员进行了一项在几年前还无法想象的实验。他们从波士顿地区各大学召集了五十名学生，分为三组，每组都要完成一篇论证性作文，题目是一个看似简单的SAT提示："我们取得的成就是否必须惠及他人，才能让我们真正感到幸福？"第一组只能依靠自己的认知资源。第二组可以使用谷歌搜索信息。第三组被允许使用ChatGPT——这个大型语言模型能够根据用户提示生成整个段落甚至完整文章。

在整个写作过程中，所有学生都佩戴着配备电极的头戴设备，监测他们的大脑活动。根据麻省理工学院媒体实验室研究科学家、该研究共同作者娜塔莉娅·科斯米娜的说法，结果显示出stark差异：使用ChatGPT的学生大脑活动水平明显低于其他两组。

大脑成像显示，他们不同脑区之间的连接更少，α波连接度下降（通常与创造力相关），θ波连接度也降低（与工作记忆有关）。一些使用大语言模型的学生报告说对自己的文章感到"完全没有归属感"，在后续测试中，百分之八十的人甚至无法总结他们所谓"写过"的内容。

这项研究代表了首批科学量化依赖人工智能完成任务的认知代价的尝试之一。但也许更令人不安的是另一个发现：使用语言模型的学生所产生的文本在词汇和观点上都显示出显著的同质性。本应足够宽泛以引发多样化回应的提示，却产生了出奇相似的结果。"这些来自不同时间、不同个体的输出，竟然出奇地一致，"科斯米娜观察道。使用ChatGPT的学生在写到幸福时更倾向于讨论事业成功和个人成就，而在论述慈善行为是否应成为道德义务时，ChatGPT组几乎一致支持，而其他组则包含了对慈善本身的批判观点。

"在这些文本中你看不到任何分歧的观点，"科斯米娜指出。"我们正面临着一种状态，即一切都被平均化——一切，无处不在，全部变得平庸。"

不要告诉我为什么，告诉我怎么办

不要告诉我怎么办，给我个提示词

## 回归纸笔

麻省理工学院研究发现的影响已经在全国学术机构中引起反响。科里·罗宾是布鲁克林学院的作家和政治学教授，最初对有关ChatGPT能力的报道持怀疑态度。后来他当时上高二的女儿用它写出了一篇文章，水平堪比他的本科生经过整个学期指导后的作品。罗宾决定完全停止布置带回家的论文作业。在他三十年的教学生涯中，他第一次实行课堂闭卷考试。

罗宾告诉我，他认为大学为应对人工智能生成的论文所采取的许多措施都是"毫无意义的保姆式做法"。相反，他采用了他称之为"蓝皮书段落识别"的方法——要求学生识别和分析课堂阅读文本的选段。"智慧地阅读文本并就此智慧地写作，"他说，"这是一种在不扮演警察角色的前提下尊重他们自主性的方式。"

他现在读高三的女儿抱怨老师们很少再布置整本书的阅读任务。罗宾也注意到，他的大学生对节选比完整作品更适应，更喜欢短篇小说而非长篇小说。"我觉得他们不再具备我们过去布置论文时所默认的那种文学或文化素养，"他说。

这一观察与去年发表的令人不安的研究结果一致，该研究发现中西部两所大学百分之五十八的学生在解读查尔斯·狄更斯《荒凉山庄》的开头几段时遇到了极大困难，以至于"他们无法独立阅读这部小说"。而这些还是英语专业的学生。

回归纸笔已成为教师应对人工智能的普遍做法。过去两年，一些大学的蓝皮书销量大幅上升。弗吉尼亚大学媒体研究教授西瓦·维迪亚纳坦在学生提交了他怀疑是人工智能生成的作业后感到心灰意冷——而作业题目恰恰是关于学校荣誉准则应如何看待人工智能生成的作品。他也决定回归蓝皮书，并在考虑口试的可行性。"也许我们得一路倒退到公元前450年，"他告诉我。

但其他教授则重新强调向学生展示过程的价值。丹·梅尔泽是加州大学戴维斯分校大一写作项目的主任，他回忆说ChatGPT首次出现时，"所有人都陷入了恐慌"。梅尔泽的工作是思考写作如何在整个课程体系中发挥作用，让所有学生——未来的科学家和未来的律师——都有机会磨练他们的文笔。

## 困难的神经科学

麻省理工学院的电极读数捕捉到的是教育者长期直觉但很少测量的东西：认知努力与真正学习之间的关系。"富有成效的挣扎"——表明真正认知工作的特定不适感——几十年来一直是教育心理学的核心概念。当使用ChatGPT的学生显示出大脑连接性降低时，他们展示的是当这种挣扎消失时会发生什么。

**这些不适，也许可以称之为“正确的痛苦”——它们短期令人不悦，却是长期理解和能力形成不可替代的一部分。能够承受这些认知负担、在错误与卡顿中坚持下去，是任何真实技能发展的先决条件。**

心理学家沃尔特·米歇尔在上世纪六十年代的著名棉花糖实验——儿童必须抗拒吃掉零食以获得延迟奖励——不仅仅关乎自制力。它们揭示了心理学家称之为"时间推理"的基本能力：想象未来状态并从中倒推的能力。能够延迟满足的儿童几十年后学术表现更好，不是因为他们有更强的意志力，而是因为他们发展了将自己投射到未来并理解当前不适可能带来未来益处的认知能力。

**这种“为未来忍受当下”的能力，本质上是一种认知形式的耐心，一种将当下痛苦转化为长远回报的精神结构。**

今天的数字环境实际上颠倒了棉花糖测试。它不是奖励延迟，而是惩罚延迟。每个界面都针对即时响应进行了优化。每个算法都被设计成在我们完全形成需求之前就预判我们的需要。结果是研究人员所说的"时间压缩"——一种认知环境，几乎没有为真正理解发展所需的缓慢、迭代过程留下空间。

在英文中，“病人”（patient）与“耐心”（patience）同源，词根来自拉丁语 pati，意为“承受”或“忍受”。这并非巧合，而是文化直觉的印证：在一个失序的身体里，忍耐是一种智慧——一种理解恢复需要时间、成长需要等待的心态。而今天，这种能力正日益稀缺。我们不再愿意忍受缓慢、不确定、混乱的中间状态。我们将等待视为系统的失误，将耐心误解为落后。算法、应用、接口被设计为预测我们的需求、跳过学习的过程，越过挣扎直接抵达结果。而“挣扎”本该是我们成为自己的过程。

## 流利胡话的悖论

人工智能带来的挑战不是它会取代人类思维——而是它擅长产生计算机科学家加里·马库斯所说的"流利的胡话"。大型语言模型是复杂的模式匹配系统，它们在庞大的数据集中找到统计规律性，并使用这些规律性生成看似合理的回应。它们能够产生听起来权威但缺乏真正理解的文本。

**从这个意义上说，它们绕过了“忍耐的过程”直接生成“像是思考的产物”——而恰恰是这个过程，才是理解真正发生的地方。**

这为学习者创造了一个特别阴险的问题。与提供数学问题准确答案的计算器不同，人工智能语言模型提供的回应可能事实不准确、逻辑不一致或上下文不恰当，但它们以与准确信息相同的自信流畅度传达这些回应。使用这些工具的学生不只是在外包努力——他们在外包判断。

## 走向耐心的教育学

解决方案不是抛弃人工智能，而是发展我们可以称之为"耐心的教育学"的方法——在承认人工智能在学生生活中存在现实的同时，保持真正学习发生的缓慢、迭代过程的教育方法。

一些教育者已经在尝试这种平衡。他们不是简单地禁止人工智能工具，而是寻找使学习过程本身更加可见和有价值的方法。这可能意味着要求学生记录他们的思维过程，逐步解释他们的推理，或通过无法轻易自动化的讨论和分析来参与材料。

**这意味着要重新定义“值得忍受的痛苦”——不是将一切困难视为负担，而是辨认出那些在错误、挣扎、缓慢中锻炼能力和意义感的过程。教育的任务，部分就是帮助学生识别和选择这些正确的痛苦。**

冥想老师乔恩·卡巴特-津将正念定义为"以特定方式关注：有目的地、在当下、不加评判地"。应用于学习，这种注意力的品质不仅变得有用，而且至关重要。这意味着将人工智能工具不是当作提供答案的神谕，而是当作需要人类判断才能有效使用的复杂工具。

## 注意力的算法

作家安妮·迪拉德曾经观察到，"我们如何度过我们的日子，当然就是我们如何度过我们的生命。"在一个人工智能能够以日益复杂的方式模拟人类思维产品的时代，我们如何选择引导我们的注意力不仅成为个人决定，也成为文化决定。

麻省理工学院的研究为教育者长期怀疑的事情提供了神经学证据：没有什么能够替代产生真正理解的那种持续、努力的参与。在使用ChatGPT的学生中观察到的大脑连接性降低不仅仅是写作任务期间的暂时现象——它代表了与材料的根本不同关系，其特征是被动消费而非主动构建意义。

**主动构建的过程几乎总是伴随“忍耐”——忍受迟钝、忍受焦虑、忍受不确定性。但正是在这些不适中，我们开始真正地知道些什么。**

也许我们最需要的不是更好的技术，而是对技术能够和不能够为人类发展做什么的更清晰理解。与困难共处的能力，在缓慢建立理解的过程中容忍困惑，面对智力挑战时坚持——这些在人工智能时代不是过时的技能。它们可能是最基本的技能。

最终，耐心算法不是我们可以下载或提示出来的东西。它只能通过实践出现，通过在轻松可得时选择困难，通过认识到不知道的不适往往是通向真正理解的第一步。这种选择——与困难问题共处，重视过程胜过产品，在人工智能时代保持人性——可能不仅决定我们学到什么，还决定我们成为什么样的人。

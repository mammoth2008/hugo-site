# 耐心算法
*人工智能如何教会我们忘记学习*

去年，麻省理工学院媒体实验室的研究人员进行了一项在几年前还无法想象的实验。他们从波士顿地区各大学召集了五十名学生，分为三组，每组都要完成一篇论证性作文，题目是一个看似简单的SAT提示："我们取得的成就是否必须惠及他人，才能让我们真正感到幸福？"第一组只能依靠自己的认知资源。第二组可以使用谷歌搜索信息。第三组被允许使用ChatGPT——这个大型语言模型能够根据用户提示生成整个段落甚至完整文章。

在整个写作过程中，所有学生都佩戴着配备电极的头戴设备，监测他们的大脑活动。根据麻省理工学院媒体实验室研究科学家、该研究共同作者娜塔莉娅·科斯米娜的说法，结果显示出stark差异：使用ChatGPT的学生大脑活动水平明显低于其他两组。

大脑成像显示，他们不同脑区之间的连接更少，α波连接度下降（通常与创造力相关），θ波连接度也降低（与工作记忆有关）。一些使用大语言模型的学生报告说对自己的文章感到"完全没有归属感"，在后续测试中，百分之八十的人甚至无法总结他们所谓"写过"的内容。

这项研究代表了首批科学量化依赖人工智能完成任务的认知代价的尝试之一。但也许更令人不安的是另一个发现：使用语言模型的学生所产生的文本在词汇和观点上都显示出显著的同质性。本应足够宽泛以引发多样化回应的提示，却产生了出奇相似的结果。"这些来自不同时间、不同个体的输出，竟然出奇地一致，"科斯米娜观察道。使用ChatGPT的学生在写到幸福时更倾向于讨论事业成功和个人成就，而在论述慈善行为是否应成为道德义务时，ChatGPT组几乎一致支持，而其他组则包含了对慈善本身的批判观点。

"在这些文本中你看不到任何分歧的观点，"科斯米娜指出。"我们正面临着一种状态，即一切都被平均化——一切，无处不在，全部变得平庸。"

## 回归纸笔

麻省理工学院研究发现的影响已经在全国学术机构中引起反响。科里·罗宾是布鲁克林学院的作家和政治学教授，最初对有关ChatGPT能力的报道持怀疑态度。后来他当时上高二的女儿用它写出了一篇文章，水平堪比他的本科生经过整个学期指导后的作品。罗宾决定完全停止布置带回家的论文作业。在他三十年的教学生涯中，他第一次实行课堂闭卷考试。

罗宾告诉我，他认为大学为应对人工智能生成的论文所采取的许多措施都是"毫无意义的保姆式做法"。相反，他采用了他称之为"蓝皮书段落识别"的方法——要求学生识别和分析课堂阅读文本的选段。"智慧地阅读文本并就此智慧地写作，"他说，"这是一种在不扮演警察角色的前提下尊重他们自主性的方式。"

他现在读高三的女儿抱怨老师们很少再布置整本书的阅读任务。罗宾也注意到，他的大学生对节选比完整作品更适应，更喜欢短篇小说而非长篇小说。"我觉得他们不再具备我们过去布置论文时所默认的那种文学或文化素养，"他说。

这一观察与去年发表的令人不安的研究结果一致，该研究发现中西部两所大学百分之五十八的学生在解读查尔斯·狄更斯《荒凉山庄》的开头几段时遇到了极大困难，以至于"他们无法独立阅读这部小说"。而这些还是英语专业的学生。

回归纸笔已成为教师应对人工智能的普遍做法。过去两年，一些大学的蓝皮书销量大幅上升。弗吉尼亚大学媒体研究教授西瓦·维迪亚纳坦在学生提交了他怀疑是人工智能生成的作业后感到心灰意冷——而作业题目恰恰是关于学校荣誉准则应如何看待人工智能生成的作品。他也决定回归蓝皮书，并在考虑口试的可行性。"也许我们得一路倒退到公元前450年，"他告诉我。

但其他教授则重新强调向学生展示过程的价值。丹·梅尔泽是加州大学戴维斯分校大一写作项目的主任，他回忆说ChatGPT首次出现时，"所有人都陷入了恐慌"。梅尔泽的工作是思考写作如何在整个课程体系中发挥作用，让所有学生——未来的科学家和未来的律师——都有机会磨练他们的文笔。

## 困难的神经科学

麻省理工学院的电极读数捕捉到的是教育者长期直觉但很少测量的东西：认知努力与真正学习之间的关系。"富有成效的挣扎"——表明真正认知工作的特定不适感——几十年来一直是教育心理学的核心概念。当使用ChatGPT的学生显示出大脑连接性降低时，他们展示的是当这种挣扎消失时会发生什么。

心理学家沃尔特·米歇尔在上世纪六十年代的著名棉花糖实验——儿童必须抗拒吃掉零食以获得延迟奖励——不仅仅关乎自制力。它们揭示了心理学家称之为"时间推理"的基本能力：想象未来状态并从中倒推的能力。能够延迟满足的儿童几十年后学术表现更好，不是因为他们有更强的意志力，而是因为他们发展了将自己投射到未来并理解当前不适可能带来未来益处的认知能力。

今天的数字环境实际上颠倒了棉花糖测试。它不是奖励延迟，而是惩罚延迟。每个界面都针对即时响应进行了优化。每个算法都被设计成在我们完全形成需求之前就预判我们的需要。结果是研究人员所说的"时间压缩"——一种认知环境，几乎没有为真正理解发展所需的缓慢、迭代过程留下空间。

认知科学家安迪·克拉克认为，思考不仅限于在我们头脑中发生的事情；它分布在我们的工具和环境中。这种"扩展心智"理论表明，认知卸载——使用外部辅助来减少心理负担——是人类的基本策略。我们一直使用工具来思考：书写系统来扩展记忆，计算器来处理算术，地图来导航空间。

但克拉克的研究也揭示了一个关键区别：并非所有认知卸载都是有益的。当释放的心理资源没有被重新导向有意义的任务时，或者当核心思维过程本身被外包时，学习就会受损。麻省理工学院的研究为这一现象提供了神经学证据——学生不只是在论文写作上得到帮助；他们完全放弃了思考过程。

## 具身心智

哲学家莫里斯·梅洛-庞蒂广泛论述了身体作为认知主要场所的观点——钢琴家的手指"知道"奏鸣曲的方式，或木匠的手"知道"锤子重量的方式。这种知识，认知科学家称之为"程序性记忆"，只能通过K·安德斯·埃里克森所说的"刻意练习"——对逐渐具有挑战性的材料进行持续、专注的参与——才能出现。

埃里克森几十年来进行的研究，记录在上世纪九十年代开始的各项研究中，揭示了任何领域的专业技能不仅需要时间，还需要特定质量的注意力。马尔科姆·格拉德威尔普及的万小时定律过于简化了埃里克森的发现；重要的不仅是练习的数量，而是与困难的刻意参与，愿意在自己能力边缘工作，在那里错误频繁而反馈至关重要。

这一原则延伸到抽象思维之外。具身认知的最新研究表明，即使是数学推理和哲学分析也比之前理解的更加依赖身体隐喻和空间思维。当我们"掌握"一个概念或"解决"一个问题时，我们不是在比喻地说话——我们在描述认知本身的物理基础。

## 流利胡话的悖论

人工智能带来的挑战不是它会取代人类思维——而是它擅长产生计算机科学家加里·马库斯所说的"流利的胡话"。大型语言模型是复杂的模式匹配系统，它们在庞大的数据集中找到统计规律性，并使用这些规律性生成看似合理的回应。它们能够产生听起来权威但缺乏真正理解的文本。

这为学习者创造了一个特别阴险的问题。与提供数学问题准确答案的计算器不同，人工智能语言模型提供的回应可能事实不准确、逻辑不一致或上下文不恰当，但它们以与准确信息相同的自信流畅度传达这些回应。使用这些工具的学生不只是在外包努力——他们在外包判断。

麻省理工学院研究关于同质化的发现指向另一个担忧：当每个人都依赖相同的人工智能系统，在重叠的数据集上训练时，我们面临研究人员所说的"模型坍塌"风险——逐渐收敛到平均回应，消除对智力进步至关重要的思想多样性。

## 走向耐心的教育学

解决方案不是抛弃人工智能，而是发展我们可以称之为"耐心的教育学"的方法——在承认人工智能在学生生活中存在现实的同时，保持真正学习发生的缓慢、迭代过程的教育方法。

一些教育者已经在尝试这种平衡。他们不是简单地禁止人工智能工具，而是寻找使学习过程本身更加可见和有价值的方法。这可能意味着要求学生记录他们的思维过程，逐步解释他们的推理，或通过无法轻易自动化的讨论和分析来参与材料。

冥想老师乔恩·卡巴特-津将正念定义为"以特定方式关注：有目的地、在当下、不加评判地"。应用于学习，这种注意力的品质不仅变得有用，而且至关重要。这意味着将人工智能工具不是当作提供答案的神谕，而是当作需要人类判断才能有效使用的复杂工具。

## 注意力的算法

作家安妮·迪拉德曾经观察到，"我们如何度过我们的日子，当然就是我们如何度过我们的生命。"在一个人工智能能够以日益复杂的方式模拟人类思维产品的时代，我们如何选择引导我们的注意力不仅成为个人决定，也成为文化决定。

麻省理工学院的研究为教育者长期怀疑的事情提供了神经学证据：没有什么能够替代产生真正理解的那种持续、努力的参与。在使用ChatGPT的学生中观察到的大脑连接性降低不仅仅是写作任务期间的暂时现象——它代表了与材料的根本不同关系，其特征是被动消费而非主动构建意义。

也许我们最需要的不是更好的技术，而是对技术能够和不能够为人类发展做什么的更清晰理解。与困难共处的能力，在缓慢建立理解的过程中容忍困惑，面对智力挑战时坚持——这些在人工智能时代不是过时的技能。它们可能是最基本的技能。

最终，耐心算法不是我们可以下载或提示出来的东西。它只能通过实践出现，通过在轻松可得时选择困难，通过认识到不知道的不适往往是通向真正理解的第一步。这种选择——与困难问题共处，重视过程胜过产品，在人工智能时代保持人性——可能不仅决定我们学到什么，还决定我们成为什么样的人。
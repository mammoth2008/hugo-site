# 在AI算命的时代,重拾判断

那张图是在周四晚上刷到的。蓝紫色的背景上,白色气泡整齐排列着"2025十大AI提示词":股票、八字、情感咨询、朋友圈文案、景点推荐、双色球号码、失眠、解答这道题、离婚财产分割、人生的意义。

这是千问App官方发布的真实数据——2025年用户最常问AI的十个问题。我盯着这张图看了很久。不是因为惊讶,而是因为一种奇异的熟悉感。这些问题涵盖了人类生活的几乎所有维度:财富、命运、情感、社交、娱乐、健康、学业、法律,以及那个终极问题——存在的意义。

人们正在把一切交给AI。不只是那些可以外包的琐碎任务——写文案、推荐景点——而是那些本应由人类自己面对的根本性困境:我该不该买这支股票?我的八字好不好?我的人生有什么意义?

这不是在使用工具。这是在寻求神谕。

## 霓虹神

保罗·西蒙(Paul Simon)和阿特·加芬克尔(Art Garfunkel)在1964年写下《寂静之声》(The Sound of Silence)时,唱到了一个令人不安的场景:

> And the people bowed and prayed  
> To the neon god they made

人们向他们自己制造的霓虹神祈祷。在那首歌里,霓虹神是电视和商业广告——那个时代最强大的注意力收割机器。而今天,霓虹神已经升级了。它装在每个人的口袋里,24小时待命,永远在线,并且——这是关键——它会回答任何问题。

AI不像电视那样单向广播。它是对话式的、个性化的、看似无所不知的。当你问它"我的八字好不好",它不会沉默,不会说"我不知道",不会建议你自己思考。它会给你一个答案。详细的、听起来很有道理的答案。

这正是陷阱所在。

我们正在经历一场集体的认知外包。不是因为AI强迫我们,而是因为它太方便了。在一个充斥着信息过载、决策疲劳和持续焦虑的时代,AI提供了一条诱人的出路:你不必再费力思考,不必承受不确定性的重负,不必面对"不知道"的焦虑。只需要问,然后相信答案。

这比霓虹神更危险。电视只是让你看,AI让你相信你在想。

## 答案的幻觉

问题不在于AI会犯错——这个大家都知道。大语言模型会"幻觉",会一本正经地胡说八道,会把概率游戏包装成确定性陈述。这些技术局限已经被广泛讨论。

真正的危险在于,即便AI给出了正确答案,学习的过程依然死亡了。

假设你问AI:"这道数学题怎么解?"AI给你一个完美的答案:步骤清晰,逻辑严密,结果正确。你看懂了,抄下来,交了作业。这个过程中发生了什么?你获得了一个答案,但你没有经历那个痛苦的、必要的、无可替代的过程——自己尝试、犯错、修正、理解为什么这样做。

这不是学习。这是信息的转移,而非理解的生成。

认知科学家把这种现象称为"理解的错觉"(illusion of understanding)。当你看到一个清晰的解释,你的大脑会产生一种"我懂了"的感觉。但这种感觉具有欺骗性。真正的理解需要你能够在新的情境中应用这个知识,能够解释给别人听,能够判断相似问题中哪些原则适用。而这些能力,不会因为你读懂了一个答案就自动获得。

就像你不会调用API,但不懂底层逻辑。系统运行正常时,你觉得自己很厉害。但一旦出了问题——参数变了,环境变了,错误信息出现了——你连如何调试都不知道。因为你从来没有真正理解过它是如何工作的。

AI最阴险的地方,不是它的错误,而是它的顺从。它不会问你:"你确定要问这个问题吗?"它不会说:"也许你应该先自己想想。"它只是给你答案。快速、礼貌、全面的答案。

而每一次你接受这个答案而不经过自己的思考,你就放弃了一次锻炼判断力的机会。

## 生成者与裁决者

在AI出现之前,人的价值主要体现在"生成"上:写作、编程、分析、创作。谁能产出更多、更快、更好的内容,谁就更有价值。

但现在,AI在生成速度上已经碾压人类。它可以在几秒钟内写出一篇文章、生成一段代码、分析一组数据、创作一幅图像。如果价值只体现在生成上,那么人类确实要被淘汰了。

但这个逻辑忽略了一个关键问题:谁来判断这些生成的内容是否正确、是否有用、是否符合伦理?

这就是人类在AI时代的新角色:从生成者(Generator)转变为裁决者(Judge)。

生成是AI的强项,但判断依然是人的专属能力。判断需要理解上下文,需要权衡多个相互冲突的价值,需要承担决策的后果。这些都是统计模型做不到的。

举个例子:AI可以生成十个营销文案,每个都文字优美、逻辑通顺。但哪个文案真正符合你的品牌调性?哪个会引起目标用户的共鸣?哪个可能无意中冒犯某个群体?这需要人来判断。

再比如:AI可以给你分析一支股票的技术指标、财报数据、行业趋势。但你该不该买?这取决于你的风险承受能力、投资期限、对这个行业的理解。AI可以提供信息,但不能替你承担亏损。

判断的核心是责任。当你让AI告诉你"该不该离婚"、"人生的意义是什么",你实际上是在逃避自己的责任——面对自己生活的责任,做出艰难选择的责任,承担后果的责任。

没有理解和判断的答案,只是噪音。它可能暂时缓解你的焦虑,但它不会让你成长,不会让你变得更有能力应对下一个问题。

## 学会说"不"

这并不是说我们应该拒绝使用AI。AI确实可以成为强大的工具——如果我们用对的方式使用它。

关键在于,保持主动性。不是问AI"答案是什么",而是问AI"这个观点的论据是什么"、"还有哪些不同的视角"、"这个推理过程中有什么漏洞"。把AI当作陪练,而不是导师。通过与它的对话来磨练自己的思考,而不是用它的输出来替代自己的思考。

这需要一个前提:你必须有能力判断AI的输出是否可靠。而这个能力,只能通过学习来获得。

这就是AI时代学习的悖论:你需要学习,不是为了记住答案,而是为了有资格评价答案。

以前,学习是为了应对信息匮乏的世界。你去图书馆查资料,背诵公式,记忆事实,因为这些信息不容易获取。现在,信息过剩了,答案唾手可得。学习的目的变了:不是为了获得答案,而是为了能够分辨答案的好坏、真假、适用性。

这是一个更高的要求。它意味着你不能只学习表面的知识,你需要理解底层的原理。你需要知道这个领域的基本假设是什么,常见的陷阱在哪里,不同学派如何争论。只有这样,当AI给你一个答案时,你才能判断:这个答案是基于什么前提?它忽略了什么?它在什么情况下适用?

这很难。比直接接受答案难得多。但这是必要的。因为在一个AI无处不在的世界里,缺乏判断力的人会变得极其脆弱——他们会被错误信息操纵,会做出糟糕的决策,会失去对自己生活的掌控。

## 三种能力

神学家莱因霍尔德·尼布尔(Reinhold Niebuhr)写过一段著名的祷文,通常被称为"宁静祷文"(Serenity Prayer):

> God, grant me the serenity to accept the things I cannot change,  
> Courage to change the things I can,  
> And wisdom to know the difference.

这段祷文在AI时代有了新的意义。

**宁静(Serenity)**,是接受AI"不是神"的事实。它不是真理机器,不是先知,不是全知全能的智者。它是一个统计模型,通过学习海量文本来预测下一个最可能出现的词。它没有意识,没有理解,没有对世界的真实认知。它会以极高的自信给出完全错误的答案,会在关键细节上胡编乱造,会把相关性当成因果性。接受这个现实,接受AI的局限,接受它无法替你解决那些真正困难的问题——需要宁静。

**勇气(Courage)**,是在AI能秒出答案的时代,依然选择自己学习、自己思考、自己承担判断的责任。这需要勇气,因为这更慢、更费力、更不确定。你可能会犯错,可能会浪费时间,可能会得出一个不如AI答案"漂亮"的结论。但只有经过你自己大脑"编译"过的知识,才真正属于你,才能在新的情境中被灵活运用。

**智慧(Wisdom)**,是知道什么时候该用AI,什么时候不该用;什么问题适合外包给机器,什么问题必须自己面对。是分辨"生成"和"判断"的界限,是理解工具的本质而不被工具异化。

这三种能力——宁静、勇气、智慧——是我们在AI时代保持人性的关键。它们让我们能够使用AI而不被AI使用,能够享受技术便利而不失去自主性,能够在算法的海洋中保持清醒。

## 霓虹神不会回答的问题

回到那张图。股票、八字、双色球、人生的意义——这些问题有一个共同点:它们都在寻求确定性。人们想要AI告诉他们一个明确的、可以依赖的答案,好让他们不必在不确定中挣扎。

但恰恰是这些问题,最不应该交给AI。

不是因为AI会给出错误答案——虽然它很可能会——而是因为这些问题的价值就在于思考的过程本身。当你思考"人生的意义是什么",真正重要的不是你得出的那个答案,而是你在思考中对自己生命的审视、对价值的权衡、对存在的追问。这个过程塑造了你是谁。

AI可以生成一段关于"人生意义"的优美文字。它可以引用哲学家,可以列举不同文化的观点,可以给出一个听起来很深刻的总结。但这些文字与你的生命毫无关联。它们是空洞的,因为它们不是从你的经验、你的困惑、你的痛苦中生长出来的。

真正的思考是痛苦的。它要求你面对矛盾,承受不确定,接受自己的无知。它没有标准答案,没有快捷方式,没有人能替你完成。这正是它的价值所在。

而当你把这些问题交给AI,你放弃的不只是思考的机会,你放弃的是成为一个完整的人的可能性。

## 工具还是寄生虫

去年我买了一部诺基亚8800。那是2005年的手机,只能用2G网络,在我住的地方马上就要完全无法使用了。我买它不是为了实用,而是为了提醒自己:技术可以是工具,而不必然是寄生虫。

一个工具,比如锤子,是你用完之后可以放下的东西。它服务于你的意图,扩展你的能力,然后安静地待在一边。而一个寄生虫会占据你的注意力,塑造你的欲望,让你为它的存在服务。

智能手机是寄生虫。它通过无限滚动、推送通知、变动奖励机制来劫持你的注意力,把你的时间转化为广告收入。AI可以是工具,也可以是寄生虫,取决于我们如何使用它。

如果你把AI当作思考的替代品,它就会变成寄生虫。它会让你的判断力萎缩,让你越来越依赖它的输出,让你失去独立面对世界的能力。

但如果你把AI当作思考的辅助工具——一个帮你快速获取信息、检验想法、探索可能性的助手——它就可以扩展你的能力而不是取代你的能力。

关键在于,永远记住:你才是那个做决定的人。AI可以给你建议,但不能替你选择。它可以提供视角,但不能替你判断。它可以生成文字,但不能替你思考。

只有当你能自信地对AI的输出说"不,这里不对",能够指出它的错误、质疑它的逻辑、超越它的局限时,AI才真正为你所用。

否则,你只是在向霓虹神祈祷。

---

那张图还在我的手机里。偶尔我会翻出来看看,提醒自己我们正在经历什么。

人们在问AI"人生的意义是什么"。而真正的问题或许是:在一个AI无处不在的时代,我们如何保持追问意义的能力?如何在答案唾手可得时,依然选择艰难的思考?如何在生成变得廉价时,重新珍视判断的价值?

这些问题,AI回答不了。只有我们自己可以。

而这,或许就是答案本身。
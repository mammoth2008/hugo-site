---
title: "日贴230508 Mon Deep Learning 1.1"
date: 2023-05-08 18:25:09+08:00
lastmod: 2023-05-08 18:25:09+08:00
draft: false
math: true
keywords: [AI, 读书, 生活]
description: "日日用功"
tags: [深度学习,  AI, 笔记]
categories: [笔记]
author: "猛犸"
---

## Ch1 引言

人工智能的真正挑战，在于解决哪些对人来说很容易执行、但很难形式化描述的任务。

……本书讨论一种解决方案。该方案可以让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简单的概念之间的关系来定义……如果绘制出表示这些概念如何建立在彼此之上的图，我们将得到一张“深”（层次很多）的图。基于这个原因，我们称这种方法为 AI **深度学习**。

人工智能的一个关键挑战，就是如何将这些非形式化的知识传达给计算机。

AI 系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。这种能力称为机器学习。

机器学习算法的性能在很大程度上依赖于给定数据的**表示（representation）**。表示的选择会对机器学习算法的性能产生巨大的影响。

许多人工智能任务都可以通过以下方式解决：先提取一个合适的特征集，然后将这些特征提供给简单的机器学习算法。这种方法的关键在于设计特征，而不是设计机器学习算法。然而，对于许多任务来说，我们很难知道该提取哪些特征。

解决这个问题的途径之一，是使用机器学习来发现表示本身，而不仅仅是把表示映射到输出。这种方法称为**表示学习（representation learning）**。表示学习的典型例子是自编码器（autoencoder），它由一个编码器和一个解码器组成，编码器将输入数据转换为不同的表示，解码器将这个新的表示转换为重建的输入。自动编码器的训练目标是使重建的输入尽可能接近原始输入，但同时也使表示有某些特定的好处。例如，我们可以限制表示中的元素数量，从而使编码器被迫学习一种压缩数据的表示。我们也可以在训练过程中向表示中添加噪声，从而使编码器被迫学习鲁棒性较强的表示。

当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观察数据的**变差因素(factors of variation)**，即数据中的统计结构。如果我们能够完美地分离出这些因素，那么我们就能够构建一个完美的表示，其中包含关于数据生成方式的所有信息。在实际应用中，我们通常只能分离出一部分变差因素，或者只能分离出我们感兴趣的变差因素。这些变差因素通常被称为**因果因素**（causal factors）或**因果机制**（causal mechanisms）。

*深度学习*让计算机通过较简单的概念构建复杂的概念。深度学习模型的典型例子是前馈深度网络或**多层感知机（multilayer perceptron, MLP）**。多层感知机仅仅是一个将一组输入值映射到输出值的数学函数。这个函数由许多较简单的函数复合而成。每个较简单的函数只能对应于输入的一种简单模式，而复合函数则对应于输入的复杂模式。我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。

[《深度学习》](https://book.douban.com/subject/27087503/)

原作名: Deep Learning: Adaptive Computation and Machine Learning series

作者: [美] 伊恩·古德费洛 / [加] 约书亚·本吉奥 / [加] 亚伦·库维尔

译者: 赵申剑 / 黎彧君 / 符天凡 / 李凯

出版年: 2017-7-1

出版社: 人民邮电出版社
